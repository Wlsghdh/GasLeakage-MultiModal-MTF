{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2a900d2-fb6d-44d6-aeea-304402f20307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "804465d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/data2/project/2025summer/jjh0709/Data/zkwgkjkjn9-2/Gas Sensors Measurements/Gas_Sensors_Measurements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bddbe138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "random = np.random.randint(0,6400,1000)\n",
    "print(len(random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b068ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[random].to_csv('1000_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from src.config import DATA_DIR_SENSOR, DATA_DIR_THERMAL, BATCH_SIZE, DEVICE, TEST_CSV_PATH\n",
    "from src.dataset import GasDataset\n",
    "from src.GasDataSet import *\n",
    "from src.transforms import transform\n",
    "from src.models.multitask_fusion_model import MultitaskFusionModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, jaccard_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "MODEL_PATH = 'Multitask_fusion_model.pt'  \n",
    "\n",
    "def plot_confusion_matrix(cm, class_names=None, save_path='confusion_matrix.png', title='Confusion Matrix'):\n",
    "    \"\"\"\n",
    "    Plot and save confusion matrix with enhanced visualization\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Create heatmap with better formatting\n",
    "    sns.heatmap(cm, \n",
    "                annot=True, \n",
    "                fmt='d', \n",
    "                cmap='Blues', \n",
    "                xticklabels=class_names if class_names else range(len(cm)), \n",
    "                yticklabels=class_names if class_names else range(len(cm)),\n",
    "                cbar_kws={'label': 'Count'},\n",
    "                square=True,\n",
    "                linewidths=0.5)\n",
    "    \n",
    "    plt.title(title, fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Rotate x-axis labels if they're long\n",
    "    if class_names and max(len(name) for name in class_names) > 8:\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    save_dir = os.path.dirname(save_path) if os.path.dirname(save_path) else '.'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    print(f\"Confusion matrix saved to {save_path}\")\n",
    "\n",
    "def plot_normalized_confusion_matrix(cm, class_names=None, save_path='confusion_matrix_normalized.png'):\n",
    "    \"\"\"\n",
    "    Plot normalized confusion matrix (percentages)\n",
    "    \"\"\"\n",
    "    # Normalize confusion matrix\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_normalized = np.nan_to_num(cm_normalized)  # Handle division by zero\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Create heatmap for normalized matrix\n",
    "    sns.heatmap(cm_normalized, \n",
    "                annot=True, \n",
    "                fmt='.2%', \n",
    "                cmap='Blues', \n",
    "                xticklabels=class_names if class_names else range(len(cm)), \n",
    "                yticklabels=class_names if class_names else range(len(cm)),\n",
    "                cbar_kws={'label': 'Percentage'},\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                vmin=0,\n",
    "                vmax=1)\n",
    "    \n",
    "    plt.title('Normalized Confusion Matrix (Percentages)', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Rotate x-axis labels if they're long\n",
    "    if class_names and max(len(name) for name in class_names) > 8:\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    save_dir = os.path.dirname(save_path) if os.path.dirname(save_path) else '.'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    print(f\"Normalized confusion matrix saved to {save_path}\")\n",
    "\n",
    "def plot_combined_confusion_matrix(cm, class_names=None, save_path='confusion_matrix_combined.png'):\n",
    "    \"\"\"\n",
    "    Plot both count and percentage in the same heatmap\n",
    "    \"\"\"\n",
    "    # Normalize confusion matrix for percentages\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_normalized = np.nan_to_num(cm_normalized)\n",
    "    \n",
    "    # Create annotations with both count and percentage\n",
    "    annotations = []\n",
    "    for i in range(len(cm)):\n",
    "        row = []\n",
    "        for j in range(len(cm[i])):\n",
    "            count = cm[i, j]\n",
    "            percentage = cm_normalized[i, j] * 100\n",
    "            row.append(f'{count}\\n({percentage:.1f}%)')\n",
    "        annotations.append(row)\n",
    "    \n",
    "    plt.figure(figsize=(14, 12))\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(cm, \n",
    "                annot=np.array(annotations),\n",
    "                fmt='', \n",
    "                cmap='Blues', \n",
    "                xticklabels=class_names if class_names else range(len(cm)), \n",
    "                yticklabels=class_names if class_names else range(len(cm)),\n",
    "                cbar_kws={'label': 'Count'},\n",
    "                square=True,\n",
    "                linewidths=0.5)\n",
    "    \n",
    "    plt.title('Confusion Matrix (Count and Percentage)', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Rotate x-axis labels if they're long\n",
    "    if class_names and max(len(name) for name in class_names) > 8:\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    save_dir = os.path.dirname(save_path) if os.path.dirname(save_path) else '.'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    print(f\"Combined confusion matrix saved to {save_path}\")\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, num_classes):\n",
    "    \"\"\"\n",
    "    Calculate various performance metrics\n",
    "    \"\"\"\n",
    "    # Convert to numpy arrays if they're tensors\n",
    "    if torch.is_tensor(y_true):\n",
    "        y_true = y_true.cpu().numpy()\n",
    "    if torch.is_tensor(y_pred):\n",
    "        y_pred = y_pred.cpu().numpy()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    jaccard = jaccard_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'jaccard_index': jaccard,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    \"\"\"\n",
    "    Print formatted metrics\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PERFORMANCE METRICS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Accuracy       : {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision      : {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall         : {metrics['recall']:.4f}\")\n",
    "    print(f\"F1-Score       : {metrics['f1_score']:.4f}\")\n",
    "    print(f\"Jaccard Index  : {metrics['jaccard_index']:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "def print_class_wise_metrics(y_true, y_pred, class_names=None):\n",
    "    \"\"\"\n",
    "    Print class-wise metrics\n",
    "    \"\"\"\n",
    "    if torch.is_tensor(y_true):\n",
    "        y_true = y_true.cpu().numpy()\n",
    "    if torch.is_tensor(y_pred):\n",
    "        y_pred = y_pred.cpu().numpy()\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    \n",
    "    print(\"\\nCLASS-WISE METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Class':<15} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    for i in range(len(precision)):\n",
    "        class_name = class_names[i] if class_names and i < len(class_names) else f\"Class {i}\"\n",
    "        print(f\"{class_name:<15} {precision[i]:<12.4f} {recall[i]:<12.4f} {f1[i]:<12.4f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "def test():\n",
    "    print(\"Loading dataset...\")\n",
    "    # Uncomment the appropriate dataset loader\n",
    "    #test_dataset = GasDataset(DATA_DIR_THERMAL, DATA_DIR_SENSOR, transform=transform)\n",
    "    test_dataset = GasDataSet(TEST_CSV_PATH, DATA_DIR_THERMAL, DATA_DIR_SENSOR, transform=transform)\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    print(\"Loading model...\")\n",
    "    model = MultitaskFusionModel().to(DEVICE)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE, weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    # Lists to store all predictions and labels\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(\"Testing model...\")\n",
    "    with torch.no_grad():\n",
    "        for thermal, sensor, label in tqdm(test_loader, desc=\"Testing\", unit=\"batch\"):\n",
    "            thermal, sensor, label = thermal.to(DEVICE), sensor.to(DEVICE), label.to(DEVICE)\n",
    "            outputs = model(thermal, sensor)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            \n",
    "            # Store predictions and labels\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Determine number of classes\n",
    "    num_classes = len(np.unique(all_labels))\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = calculate_metrics(all_labels, all_preds, num_classes)\n",
    "    \n",
    "    # Print overall metrics\n",
    "    print_metrics(metrics)\n",
    "    \n",
    "    # Define class names (modify based on your dataset)\n",
    "    class_names = [f\"Gas_{i}\" for i in range(num_classes)]\n",
    "    # For actual gas types, use something like:\n",
    "    # class_names = ['No Gas', 'Methane', 'Ethane', 'Propane', 'Butane', 'CO2']\n",
    "    \n",
    "    # Print class-wise metrics\n",
    "    print_class_wise_metrics(all_labels, all_preds, class_names)\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = 'results'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Plot different versions of confusion matrix\n",
    "    print(\"\\nGenerating confusion matrix visualizations...\")\n",
    "    \n",
    "    # 1. Standard confusion matrix (counts)\n",
    "    plot_confusion_matrix(\n",
    "        metrics['confusion_matrix'], \n",
    "        class_names, \n",
    "        save_path=f'{output_dir}/confusion_matrix_counts.png',\n",
    "        title='Confusion Matrix (Counts)'\n",
    "    )\n",
    "    \n",
    "    # 2. Normalized confusion matrix (percentages)\n",
    "    plot_normalized_confusion_matrix(\n",
    "        metrics['confusion_matrix'], \n",
    "        class_names, \n",
    "        save_path=f'{output_dir}/confusion_matrix_normalized.png'\n",
    "    )\n",
    "    \n",
    "    # 3. Combined confusion matrix (counts and percentages)\n",
    "    plot_combined_confusion_matrix(\n",
    "        metrics['confusion_matrix'], \n",
    "        class_names, \n",
    "        save_path=f'{output_dir}/confusion_matrix_combined.png'\n",
    "    )\n",
    "    \n",
    "    # Print confusion matrix in text format\n",
    "    print(\"\\nCONFUSION MATRIX\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Rows: True Labels, Columns: Predicted Labels\")\n",
    "    print(metrics['confusion_matrix'])\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Additional analysis\n",
    "    print(f\"\\nTotal samples: {len(all_labels)}\")\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print(f\"Class distribution:\")\n",
    "    unique, counts = np.unique(all_labels, return_counts=True)\n",
    "    for class_idx, count in zip(unique, counts):\n",
    "        class_name = class_names[class_idx] if class_idx < len(class_names) else f\"Class {class_idx}\"\n",
    "        print(f\"  {class_name}: {count} ({count/len(all_labels)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nAll visualization files saved in '{output_dir}/' directory\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set matplotlib backend for better compatibility\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')  # Use non-interactive backend\n",
    "    plt.ioff()  # Turn off interactive mode\n",
    "    \n",
    "    test()\n",
    "    \n",
    "    # Show plots at the end if needed\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b399217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded: 180 samples from /data2/project/2025summer/jjh0709/git/GasLeakage-MultiModal-MTF/data/TEST_DATA.csv\n",
      "Loading model...\n",
      "Testing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 23/23 [00:03<00:00,  7.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PERFORMANCE METRICS\n",
      "==================================================\n",
      "Accuracy       : 0.9222\n",
      "Precision      : 0.9392\n",
      "Recall         : 0.9222\n",
      "F1-Score       : 0.9219\n",
      "AUROC          : 0.9989\n",
      "==================================================\n",
      "\n",
      "CLASS-WISE METRICS\n",
      "============================================================\n",
      "Class           Precision    Recall       F1-Score    \n",
      "------------------------------------------------------------\n",
      "Gas_0           1.0000       1.0000       1.0000      \n",
      "Gas_1           0.7812       1.0000       0.8772      \n",
      "Gas_2           1.0000       0.7667       0.8679      \n",
      "Gas_3           1.0000       1.0000       1.0000      \n",
      "============================================================\n",
      "\n",
      "Generating confusion matrix visualizations...\n",
      "Confusion matrix saved to results/confusion_matrix_counts.png\n",
      "Normalized confusion matrix saved to results/confusion_matrix_normalized.png\n",
      "Combined confusion matrix saved to results/confusion_matrix_combined.png\n",
      "\n",
      "CONFUSION MATRIX\n",
      "==================================================\n",
      "Rows: True Labels, Columns: Predicted Labels\n",
      "[[30  0  0  0]\n",
      " [ 0 50  0  0]\n",
      " [ 0 14 46  0]\n",
      " [ 0  0  0 40]]\n",
      "==================================================\n",
      "\n",
      "Total samples: 180\n",
      "Number of classes: 4\n",
      "Class distribution:\n",
      "  Gas_0: 30 (16.7%)\n",
      "  Gas_1: 50 (27.8%)\n",
      "  Gas_2: 60 (33.3%)\n",
      "  Gas_3: 40 (22.2%)\n",
      "\n",
      "All visualization files saved in 'results/' directory\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from src.config import DATA_DIR_SENSOR, DATA_DIR_THERMAL, BATCH_SIZE, DEVICE, TEST_CSV_PATH\n",
    "from src.dataset import GasDataset\n",
    "from src.GasDataSet import *\n",
    "from src.transforms import transform\n",
    "from src.models.multitask_fusion_model import MultitaskFusionModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "MODEL_PATH = 'Multitask_fusion_model.pt'  \n",
    "\n",
    "def plot_confusion_matrix(cm, class_names=None, save_path='confusion_matrix.png', title='Confusion Matrix'):\n",
    "    \"\"\"\n",
    "    Plot and save confusion matrix with enhanced visualization\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Create heatmap with better formatting\n",
    "    sns.heatmap(cm, \n",
    "                annot=True, \n",
    "                fmt='d', \n",
    "                cmap='Blues', \n",
    "                xticklabels=class_names if class_names else range(len(cm)), \n",
    "                yticklabels=class_names if class_names else range(len(cm)),\n",
    "                cbar_kws={'label': 'Count'},\n",
    "                square=True,\n",
    "                linewidths=0.5)\n",
    "    \n",
    "    plt.title(title, fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Rotate x-axis labels if they're long\n",
    "    if class_names and max(len(name) for name in class_names) > 8:\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    save_dir = os.path.dirname(save_path) if os.path.dirname(save_path) else '.'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    print(f\"Confusion matrix saved to {save_path}\")\n",
    "\n",
    "def plot_normalized_confusion_matrix(cm, class_names=None, save_path='confusion_matrix_normalized.png'):\n",
    "    \"\"\"\n",
    "    Plot normalized confusion matrix (percentages)\n",
    "    \"\"\"\n",
    "    # Normalize confusion matrix\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_normalized = np.nan_to_num(cm_normalized)  # Handle division by zero\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Create heatmap for normalized matrix\n",
    "    sns.heatmap(cm_normalized, \n",
    "                annot=True, \n",
    "                fmt='.2%', \n",
    "                cmap='Blues', \n",
    "                xticklabels=class_names if class_names else range(len(cm)), \n",
    "                yticklabels=class_names if class_names else range(len(cm)),\n",
    "                cbar_kws={'label': 'Percentage'},\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                vmin=0,\n",
    "                vmax=1)\n",
    "    \n",
    "    plt.title('Normalized Confusion Matrix (Percentages)', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Rotate x-axis labels if they're long\n",
    "    if class_names and max(len(name) for name in class_names) > 8:\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    save_dir = os.path.dirname(save_path) if os.path.dirname(save_path) else '.'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    print(f\"Normalized confusion matrix saved to {save_path}\")\n",
    "\n",
    "def plot_combined_confusion_matrix(cm, class_names=None, save_path='confusion_matrix_combined.png'):\n",
    "    \"\"\"\n",
    "    Plot both count and percentage in the same heatmap\n",
    "    \"\"\"\n",
    "    # Normalize confusion matrix for percentages\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_normalized = np.nan_to_num(cm_normalized)\n",
    "    \n",
    "    # Create annotations with both count and percentage\n",
    "    annotations = []\n",
    "    for i in range(len(cm)):\n",
    "        row = []\n",
    "        for j in range(len(cm[i])):\n",
    "            count = cm[i, j]\n",
    "            percentage = cm_normalized[i, j] * 100\n",
    "            row.append(f'{count}\\n({percentage:.1f}%)')\n",
    "        annotations.append(row)\n",
    "    \n",
    "    plt.figure(figsize=(14, 12))\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(cm, \n",
    "                annot=np.array(annotations),\n",
    "                fmt='', \n",
    "                cmap='Blues', \n",
    "                xticklabels=class_names if class_names else range(len(cm)), \n",
    "                yticklabels=class_names if class_names else range(len(cm)),\n",
    "                cbar_kws={'label': 'Count'},\n",
    "                square=True,\n",
    "                linewidths=0.5)\n",
    "    \n",
    "    plt.title('Confusion Matrix (Count and Percentage)', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Rotate x-axis labels if they're long\n",
    "    if class_names and max(len(name) for name in class_names) > 8:\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    save_dir = os.path.dirname(save_path) if os.path.dirname(save_path) else '.'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    print(f\"Combined confusion matrix saved to {save_path}\")\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_proba, num_classes):\n",
    "    \"\"\"\n",
    "    Calculate various performance metrics including AUROC\n",
    "    \"\"\"\n",
    "    # Convert to numpy arrays if they're tensors\n",
    "    if torch.is_tensor(y_true):\n",
    "        y_true = y_true.cpu().numpy()\n",
    "    if torch.is_tensor(y_pred):\n",
    "        y_pred = y_pred.cpu().numpy()\n",
    "    if torch.is_tensor(y_proba):\n",
    "        y_proba = y_proba.cpu().numpy()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Calculate AUROC\n",
    "    try:\n",
    "        if num_classes == 2:\n",
    "            # Binary classification\n",
    "            auroc = roc_auc_score(y_true, y_proba[:, 1])\n",
    "        else:\n",
    "            # Multi-class classification (one-vs-rest)\n",
    "            auroc = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not calculate AUROC: {e}\")\n",
    "        auroc = 0.0\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auroc': auroc,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    \"\"\"\n",
    "    Print formatted metrics\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PERFORMANCE METRICS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Accuracy       : {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision      : {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall         : {metrics['recall']:.4f}\")\n",
    "    print(f\"F1-Score       : {metrics['f1_score']:.4f}\")\n",
    "    print(f\"AUROC          : {metrics['auroc']:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "def print_class_wise_metrics(y_true, y_pred, class_names=None):\n",
    "    \"\"\"\n",
    "    Print class-wise metrics\n",
    "    \"\"\"\n",
    "    if torch.is_tensor(y_true):\n",
    "        y_true = y_true.cpu().numpy()\n",
    "    if torch.is_tensor(y_pred):\n",
    "        y_pred = y_pred.cpu().numpy()\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    \n",
    "    print(\"\\nCLASS-WISE METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Class':<15} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    for i in range(len(precision)):\n",
    "        class_name = class_names[i] if class_names and i < len(class_names) else f\"Class {i}\"\n",
    "        print(f\"{class_name:<15} {precision[i]:<12.4f} {recall[i]:<12.4f} {f1[i]:<12.4f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "def test():\n",
    "    print(\"Loading dataset...\")\n",
    "    # Uncomment the appropriate dataset loader\n",
    "    #test_dataset = GasDataset(DATA_DIR_THERMAL, DATA_DIR_SENSOR, transform=transform)\n",
    "    test_dataset = GasDataSet(TEST_CSV_PATH, DATA_DIR_THERMAL, DATA_DIR_SENSOR, transform=transform)\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    print(\"Loading model...\")\n",
    "    model = MultitaskFusionModel().to(DEVICE)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE, weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    # Lists to store all predictions, probabilities, and labels\n",
    "    all_preds = []\n",
    "    all_proba = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(\"Testing model...\")\n",
    "    with torch.no_grad():\n",
    "        for thermal, sensor, label in tqdm(test_loader, desc=\"Testing\", unit=\"batch\"):\n",
    "            thermal, sensor, label = thermal.to(DEVICE), sensor.to(DEVICE), label.to(DEVICE)\n",
    "            outputs = model(thermal, sensor)\n",
    "            \n",
    "            # Get predicted classes\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            \n",
    "            # Get probabilities using softmax\n",
    "            proba = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            # Store predictions, probabilities, and labels\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_proba.append(proba.cpu().numpy())\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_proba = np.vstack(all_proba)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Determine number of classes\n",
    "    num_classes = len(np.unique(all_labels))\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = calculate_metrics(all_labels, all_preds, all_proba, num_classes)\n",
    "    \n",
    "    # Print overall metrics\n",
    "    print_metrics(metrics)\n",
    "    \n",
    "    # Define class names (modify based on your dataset)\n",
    "    class_names = [f\"Gas_{i}\" for i in range(num_classes)]\n",
    "    # For actual gas types, use something like:\n",
    "    # class_names = ['No Gas', 'Methane', 'Ethane', 'Propane', 'Butane', 'CO2']\n",
    "    \n",
    "    # Print class-wise metrics\n",
    "    print_class_wise_metrics(all_labels, all_preds, class_names)\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = 'results'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Plot different versions of confusion matrix\n",
    "    print(\"\\nGenerating confusion matrix visualizations...\")\n",
    "    \n",
    "    # 1. Standard confusion matrix (counts)\n",
    "    plot_confusion_matrix(\n",
    "        metrics['confusion_matrix'], \n",
    "        class_names, \n",
    "        save_path=f'{output_dir}/confusion_matrix_counts.png',\n",
    "        title='Confusion Matrix (Counts)'\n",
    "    )\n",
    "    \n",
    "    # 2. Normalized confusion matrix (percentages)\n",
    "    plot_normalized_confusion_matrix(\n",
    "        metrics['confusion_matrix'], \n",
    "        class_names, \n",
    "        save_path=f'{output_dir}/confusion_matrix_normalized.png'\n",
    "    )\n",
    "    \n",
    "    # 3. Combined confusion matrix (counts and percentages)\n",
    "    plot_combined_confusion_matrix(\n",
    "        metrics['confusion_matrix'], \n",
    "        class_names, \n",
    "        save_path=f'{output_dir}/confusion_matrix_combined.png'\n",
    "    )\n",
    "    \n",
    "    # Print confusion matrix in text format\n",
    "    print(\"\\nCONFUSION MATRIX\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Rows: True Labels, Columns: Predicted Labels\")\n",
    "    print(metrics['confusion_matrix'])\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Additional analysis\n",
    "    print(f\"\\nTotal samples: {len(all_labels)}\")\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print(f\"Class distribution:\")\n",
    "    unique, counts = np.unique(all_labels, return_counts=True)\n",
    "    for class_idx, count in zip(unique, counts):\n",
    "        class_name = class_names[class_idx] if class_idx < len(class_names) else f\"Class {class_idx}\"\n",
    "        print(f\"  {class_name}: {count} ({count/len(all_labels)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nAll visualization files saved in '{output_dir}/' directory\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set matplotlib backend for better compatibility\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')  # Use non-interactive backend\n",
    "    plt.ioff()  # Turn off interactive mode\n",
    "    \n",
    "    test()\n",
    "    \n",
    "    # Show plots at the end if needed\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff075f5-7def-4bdc-b1b5-e5e2b6dee4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 완료\n",
      "Train shape: (21693, 53)\n",
      "Test shape: (15004, 52)\n",
      "\n",
      "제거 후 Train shape: (21693, 23)\n",
      "제거 후 Test shape: (15004, 22)\n",
      "\n",
      "클래스 분포:\n",
      "target\n",
      "0     1033\n",
      "1     1033\n",
      "2     1033\n",
      "3     1033\n",
      "4     1033\n",
      "5     1033\n",
      "6     1033\n",
      "7     1033\n",
      "8     1033\n",
      "9     1033\n",
      "10    1033\n",
      "11    1033\n",
      "12    1033\n",
      "13    1033\n",
      "14    1033\n",
      "15    1033\n",
      "16    1033\n",
      "17    1033\n",
      "18    1033\n",
      "19    1033\n",
      "20    1033\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "==================================================\n",
      "PolynomialFeatures (degree=5)\n",
      "==================================================\n",
      "원본 특성 수: 22\n",
      "Degree 5 특성 수: 2299\n",
      "\n",
      "사용 중인 디바이스: cuda\n",
      "\n",
      "QDA 학습 중...\n",
      "QDA 학습 완료!\n",
      "\n",
      "Train 데이터 예측 중...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 121\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# Train 성과 평가\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTrain 데이터 예측 중...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m Y_train_pred_t = qda_predict(X_train_t)\n\u001b[32m    122\u001b[39m Y_train_pred = Y_train_pred_t.cpu().numpy()\n\u001b[32m    124\u001b[39m accuracy = accuracy_score(Y_train, Y_train_pred)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 109\u001b[39m, in \u001b[36mqda_predict\u001b[39m\u001b[34m(X)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_classes):\n\u001b[32m    108\u001b[39m     diff = (x - means[k]).unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     inv_cov = torch.inverse(covs[k])\n\u001b[32m    110\u001b[39m     term = -\u001b[32m0.5\u001b[39m * torch.mm(torch.mm(diff, inv_cov), diff.T)\n\u001b[32m    111\u001b[39m     score = term - \u001b[32m0.5\u001b[39m * torch.logdet(covs[k]) + torch.log(priors[k])\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# ============================================\n",
    "# 데이터 로드\n",
    "# ============================================\n",
    "train_data = pd.read_csv(\"open (2)//train.csv\", index_col='ID')\n",
    "test_data = pd.read_csv(\"open (2)//test.csv\", index_col='ID')\n",
    "sample_submission = pd.read_csv(\"open (2)//sample_submission.csv\", index_col='ID')\n",
    "\n",
    "print(\"데이터 로드 완료\")\n",
    "print(f\"Train shape: {train_data.shape}\")\n",
    "print(f\"Test shape: {test_data.shape}\\n\")\n",
    "\n",
    "# ============================================\n",
    "# 특성 제거\n",
    "# ============================================\n",
    "drop_columns = [5,7,8,9,12,13,14,16,18,19,20,21,22,24,25,28,29,30,31,33,35,36,38,41,42,44,46,47,49,51]\n",
    "\n",
    "for i in drop_columns:\n",
    "    col_name = f\"X_{i:02d}\"\n",
    "    train_data = train_data.drop(col_name, axis=1, errors='ignore')\n",
    "    test_data = test_data.drop(col_name, axis=1, errors='ignore')\n",
    "\n",
    "print(f\"제거 후 Train shape: {train_data.shape}\")\n",
    "print(f\"제거 후 Test shape: {test_data.shape}\\n\")\n",
    "\n",
    "# ============================================\n",
    "# X, Y 분리\n",
    "# ============================================\n",
    "X_train = train_data.drop('target', axis=1)\n",
    "Y_train = train_data['target']\n",
    "\n",
    "print(\"클래스 분포:\")\n",
    "print(Y_train.value_counts().sort_index(), \"\\n\")\n",
    "\n",
    "# ============================================\n",
    "# PolynomialFeatures (degree=2 or 5 가능)\n",
    "# ============================================\n",
    "print(\"=\"*50)\n",
    "print(\"PolynomialFeatures (degree=5)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "poly = PolynomialFeatures(degree=5, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(test_data)\n",
    "\n",
    "print(f\"원본 특성 수: {X_train.shape[1]}\")\n",
    "print(f\"Degree 5 특성 수: {X_train_poly.shape[1]}\\n\")\n",
    "\n",
    "# ============================================\n",
    "# 데이터 정규화\n",
    "# ============================================\n",
    "scaler = StandardScaler()\n",
    "X_train_poly = scaler.fit_transform(X_train_poly)\n",
    "X_test_poly = scaler.transform(X_test_poly)\n",
    "\n",
    "# ============================================\n",
    "# PyTorch Tensor로 변환 (GPU)\n",
    "# ============================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"사용 중인 디바이스: {device}\\n\")\n",
    "\n",
    "X_train_t = torch.tensor(X_train_poly, dtype=torch.float32, device=device)\n",
    "Y_train_t = torch.tensor(Y_train.values, dtype=torch.long, device=device)\n",
    "X_test_t  = torch.tensor(X_test_poly, dtype=torch.float32, device=device)\n",
    "\n",
    "# ============================================\n",
    "# QDA 수식 구현\n",
    "# ============================================\n",
    "print(\"QDA 학습 중...\")\n",
    "\n",
    "classes = torch.unique(Y_train_t)\n",
    "num_classes = len(classes)\n",
    "num_features = X_train_t.shape[1]\n",
    "\n",
    "means = []\n",
    "covs = []\n",
    "priors = []\n",
    "\n",
    "for c in classes:\n",
    "    Xc = X_train_t[Y_train_t == c]\n",
    "    mean_c = Xc.mean(dim=0)\n",
    "    means.append(mean_c)\n",
    "    \n",
    "    cov_c = torch.cov(Xc.T)\n",
    "    covs.append(cov_c + 1e-6 * torch.eye(num_features, device=device))  # 안정성 위한 작은 값 추가\n",
    "    \n",
    "    priors.append(len(Xc) / len(X_train_t))\n",
    "\n",
    "means = torch.stack(means)\n",
    "covs = torch.stack(covs)\n",
    "priors = torch.tensor(priors, device=device)\n",
    "\n",
    "print(\"QDA 학습 완료!\\n\")\n",
    "\n",
    "# ============================================\n",
    "# 예측 함수 정의\n",
    "# ============================================\n",
    "def qda_predict(X):\n",
    "    preds = []\n",
    "    for x in X:\n",
    "        scores = []\n",
    "        for k in range(num_classes):\n",
    "            diff = (x - means[k]).unsqueeze(0)\n",
    "            inv_cov = torch.inverse(covs[k])\n",
    "            term = -0.5 * torch.mm(torch.mm(diff, inv_cov), diff.T)\n",
    "            score = term - 0.5 * torch.logdet(covs[k]) + torch.log(priors[k])\n",
    "            scores.append(score)\n",
    "        scores = torch.cat(scores).flatten()\n",
    "        preds.append(torch.argmax(scores))\n",
    "    return torch.stack(preds)\n",
    "\n",
    "# ============================================\n",
    "# Train 성과 평가\n",
    "# ============================================\n",
    "print(\"Train 데이터 예측 중...\")\n",
    "Y_train_pred_t = qda_predict(X_train_t)\n",
    "Y_train_pred = Y_train_pred_t.cpu().numpy()\n",
    "\n",
    "accuracy = accuracy_score(Y_train, Y_train_pred)\n",
    "f1 = f1_score(Y_train, Y_train_pred, average='weighted')\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"Train 성과\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\\n\")\n",
    "\n",
    "# ============================================\n",
    "# Test 데이터 예측\n",
    "# ============================================\n",
    "print(\"Test 데이터 예측 중...\")\n",
    "Y_test_pred_t = qda_predict(X_test_t)\n",
    "predictions = Y_test_pred_t.cpu().numpy()\n",
    "\n",
    "print(\"예측 완료!\")\n",
    "print(f\"예측값 개수: {len(predictions)}\\n\")\n",
    "print(\"예측 클래스 분포:\")\n",
    "print(pd.Series(predictions).value_counts().sort_index(), \"\\n\")\n",
    "\n",
    "# ============================================\n",
    "# 제출 파일 저장\n",
    "# ============================================\n",
    "sample_submission['target'] = predictions.astype(int)\n",
    "output_path = \"open (2)//submission_qda_gpu.csv\"\n",
    "sample_submission.to_csv(output_path)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"✓ 완료! GPU QDA 결과 저장됨\")\n",
    "print(f\"저장 경로: {output_path}\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace59cfe-3ec5-40ea-a1d7-0405fc1eb703",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 15.13 GiB. GPU 0 has a total capacity of 23.59 GiB of which 464.88 MiB is free. Process 2040555 has 990.00 MiB memory in use. Including non-PyTorch memory, this process has 22.13 GiB memory in use. Of the allocated memory 21.88 GiB is allocated by PyTorch, and 1.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m X_train_t = torch.tensor(X_train_poly, dtype=torch.float32, device=device)\n\u001b[32m     37\u001b[39m Y_train_t = torch.tensor(Y_train.values, dtype=torch.long, device=device)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m X_test_t  = torch.tensor(X_test_poly, dtype=torch.float32, device=device)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Naive QDA (대각 공분산) 학습 (기존과 동일)\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[32m     43\u001b[39m classes = torch.unique(Y_train_t)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 15.13 GiB. GPU 0 has a total capacity of 23.59 GiB of which 464.88 MiB is free. Process 2040555 has 990.00 MiB memory in use. Including non-PyTorch memory, this process has 22.13 GiB memory in use. Of the allocated memory 21.88 GiB is allocated by PyTorch, and 1.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# ⭐️ 추가된 라이브러리: DataLoader와 TensorDataset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ============================================\n",
    "# 데이터 로드 및 전처리 (기존과 동일)\n",
    "# ============================================\n",
    "train_data = pd.read_csv(\"open (2)//train.csv\", index_col='ID')\n",
    "test_data = pd.read_csv(\"open (2)//test.csv\", index_col='ID')\n",
    "sample_submission = pd.read_csv(\"open (2)//sample_submission.csv\", index_col='ID')\n",
    "\n",
    "drop_columns = [25,33,36,38]\n",
    "for i in drop_columns:\n",
    "    col_name = f\"X_{i:02d}\"\n",
    "    train_data = train_data.drop(col_name, axis=1, errors='ignore')\n",
    "    test_data = test_data.drop(col_name, axis=1, errors='ignore')\n",
    "\n",
    "X_train = train_data.drop('target', axis=1)\n",
    "Y_train = train_data['target']\n",
    "\n",
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(test_data)\n",
    "num_features = X_train_poly.shape[1] \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_poly = scaler.fit_transform(X_train_poly)\n",
    "X_test_poly = scaler.transform(X_test_poly)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train_t = torch.tensor(X_train_poly, dtype=torch.float32, device=device)\n",
    "Y_train_t = torch.tensor(Y_train.values, dtype=torch.long, device=device)\n",
    "X_test_t  = torch.tensor(X_test_poly, dtype=torch.float32, device=device)\n",
    "\n",
    "# ============================================\n",
    "# Naive QDA (대각 공분산) 학습 (기존과 동일)\n",
    "# ============================================\n",
    "classes = torch.unique(Y_train_t)\n",
    "num_classes = len(classes)\n",
    "\n",
    "means, vars_, priors = [], [], []\n",
    "\n",
    "for c in classes:\n",
    "    Xc = X_train_t[Y_train_t == c]\n",
    "    means.append(Xc.mean(dim=0))\n",
    "    vars_.append(Xc.var(dim=0) + 1e-6)\n",
    "    priors.append(len(Xc) / len(X_train_t))\n",
    "\n",
    "means = torch.stack(means) # [K, D]\n",
    "vars_ = torch.stack(vars_) # [K, D]\n",
    "priors = torch.tensor(priors, device=device) # [K]\n",
    "\n",
    "# 상수항을 미리 계산\n",
    "inv_vars = 1.0 / vars_ # [K, D]\n",
    "log_det_term = -0.5 * torch.sum(torch.log(vars_), dim=1) # [K]\n",
    "log_prior_term = torch.log(priors) # [K]\n",
    "\n",
    "print(\"Naive QDA 학습 완료! (모델 파라미터 저장)\")\n",
    "\n",
    "# ============================================\n",
    "# ⭐️ 배치 예측 함수 정의 ⭐️\n",
    "# ============================================\n",
    "def batch_predict(X_tensor, batch_size=1024):\n",
    "    \"\"\"\n",
    "    GPU OOM을 방지하기 위해 데이터를 배치 단위로 예측합니다.\n",
    "    \"\"\"\n",
    "    # 1. DataLoader 설정\n",
    "    dataset = TensorDataset(X_tensor)\n",
    "    # 메모리 상황에 따라 batch_size를 더 줄일 수 있습니다 (예: 512, 256)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    all_preds = []\n",
    "    \n",
    "    # 2. 배치별 예측 수행\n",
    "    for [X_batch] in loader:\n",
    "        # X_batch.shape: [B, D]\n",
    "        \n",
    "        # [B, D] -> [B, 1, D] - [K, D] -> [B, K, D]\n",
    "        diff = (X_batch.unsqueeze(1) - means) \n",
    "        \n",
    "        # Mahalanobis distance (요소별 연산)\n",
    "        # [B, K, D] * [K, D] -> sum over D -> [B, K]\n",
    "        mahalanobis_term = -0.5 * torch.sum(diff * diff * inv_vars, dim=2) \n",
    "        \n",
    "        # 최종 점수 (로그 사후 확률에 비례)\n",
    "        # [B, K] + [K] + [K] -> [B, K]\n",
    "        scores = mahalanobis_term + log_det_term + log_prior_term\n",
    "        \n",
    "        preds = torch.argmax(scores, dim=1)\n",
    "        all_preds.append(preds)\n",
    "        \n",
    "    # 3. 모든 배치 결과 취합\n",
    "    return torch.cat(all_preds)\n",
    "\n",
    "# ============================================\n",
    "# Train 성과 평가 (배치 적용)\n",
    "# ============================================\n",
    "print(\"\\nTrain 데이터 배치 예측 중...\")\n",
    "# ⭐️ 배치 예측 함수 사용 ⭐️\n",
    "Y_train_pred_t = batch_predict(X_train_t, batch_size=1024) \n",
    "Y_train_pred = Y_train_pred_t.cpu().numpy()\n",
    "\n",
    "accuracy = accuracy_score(Y_train, Y_train_pred)\n",
    "f1 = f1_score(Y_train, Y_train_pred, average='weighted')\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"Train 성과 (Naive QDA, 배치 적용)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\\n\")\n",
    "\n",
    "# ============================================\n",
    "# Test 데이터 예측 (배치 적용)\n",
    "# ============================================\n",
    "print(\"Test 데이터 배치 예측 중...\")\n",
    "# ⭐️ 배치 예측 함수 사용 ⭐️\n",
    "Y_test_pred_t = batch_predict(X_test_t, batch_size=1024)\n",
    "predictions = Y_test_pred_t.cpu().numpy()\n",
    "\n",
    "print(\"예측 완료!\")\n",
    "\n",
    "# ============================================\n",
    "# 제출 파일 저장\n",
    "# ============================================\n",
    "sample_submission['target'] = predictions.astype(int)\n",
    "output_path = \"open (2)//submission_naive_qda_batch_gpu.csv\"\n",
    "sample_submission.to_csv(output_path)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"✓ 완료! GPU Naive QDA (배치) 결과 저장됨\")\n",
    "print(f\"저장 경로: {output_path}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f0ea8ca-0da4-4643-adb5-193d1d729115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc # 가비지 컬렉터 import\n",
    "\n",
    "# 이전 작업에서 생성된 불필요한 변수 삭제 및 메모리 확보\n",
    "del X_train_poly # NumPy 배열은 더 이상 GPU에 필요하지 않으므로 삭제해도 무방\n",
    "gc.collect() \n",
    "torch.cuda.empty_cache() # ⭐️ 가장 중요한 코드: PyTorch의 GPU 캐시 비우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352cc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3756795/2815907429.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(\"data2/project/2025summer/mym470/Gas-Detection-and-Identification-Using-Multimodal/outputs/model.pt\", map_location=\"cpu\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data2/project/2025summer/mym470/Gas-Detection-and-Identification-Using-Multimodal/outputs/model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmobile_optimizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m optimize_for_mobile\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model = torch.load(\u001b[33m\"\u001b[39m\u001b[33mdata2/project/2025summer/mym470/Gas-Detection-and-Identification-Using-Multimodal/outputs/model.pt\u001b[39m\u001b[33m\"\u001b[39m, map_location=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m) \n\u001b[32m      5\u001b[39m model.eval()\n\u001b[32m      7\u001b[39m ts = torch.jit.trace(model) \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jjh/lib/python3.11/site-packages/torch/serialization.py:1319\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1317\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1321\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1322\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1323\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1324\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jjh/lib/python3.11/site-packages/torch/serialization.py:659\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    658\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[32m    660\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    661\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jjh/lib/python3.11/site-packages/torch/serialization.py:640\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data2/project/2025summer/mym470/Gas-Detection-and-Identification-Using-Multimodal/outputs/model.pt'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "model = torch.jit.load(\n",
    "    \"data2/project/2025summer/mym470/Gas-Detection-and-Identification-Using-Multimodal/outputs/model.pt\",\n",
    "    map_location=\"cpu\"\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "optimized = optimize_for_mobile(model)\n",
    "\n",
    "optimized._save_for_lite_interpreter(\"data2/project/2025summer/mym470/Gas-Detection-and-Identification-Using-Multimodal/outputs/model.ptl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jjh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
